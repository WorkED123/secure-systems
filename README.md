<h1> Lesson 18.2: Machine Learning and Artificial Intelligence  </h1>
<h2> Summary</h2>

<p1>In this lesson students will examine the emerging technology of AI and machine learning and how it relates to the cyber landscape..</p1>
<br>

<h2>Learning Objectives</h2>
<ul>
<li>Contrast Narrow AI and AGI.</li>
  <br>
<li>Know cybersecurity applications of AI and Machine Learning.</li><br>
  
<li>Give an example of Narrow AI.</li>

</ul>

<h2>Vocabulary and Acronyms</h2>

<ul>
<li>

  **Artificial Intelligence - AI**</li>
  
<li>

**Machine Learning**</li>
  
<li>
  
**Algorithms**</li>
  

</ul>



<h2>Lesson Prerequisites</h2>
<p1>Any topical or subject matter to prepare for the lesson. In Advanced Cyber Lessons, previous Lessons can be referenced. </p1>
<br>


<h2>What is Machine Learning?</h2>
<ul>
	<li>Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves. </li><br>
	<li>The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide.  
</li><br>
	<li>The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly. But, using the classic algorithms of machine learning, text is considered as a sequence of keywords; instead, an approach based on semantic analysis mimics the human ability to understand the meaning of a text. </li><br>
	
</ul>

<h2>Machine Learning Algorithms</h2>

<ul>
	<li>Machine learning algorithms are often categorized as <ins>supervised or unsupervised</ins>. </li><br>
	<li><ins>Supervised machine:</ins> 
			<ul>
			<li>Learning algorithms can apply what has been learned in the past to new data using labeled examples to predict future events. Starting from the analysis of a known training dataset, the learning algorithm produces an inferred function to make predictions about the output values. The system is able to provide targets for any new input after sufficient training. The learning algorithm can also compare its output with the correct, intended output and find errors in order to modify the model accordingly.</li>
		</ul>

<li><ins>Unsupervised machine:</ins> 
	
<ul>
		<li>Learning algorithms are used when the information used to train is neither classified nor labeled. Unsupervised learning studies how systems can infer a function to describe a hidden structure from unlabeled data. The system doesn’t figure out the right output, but it explores the data and can draw inferences from datasets to describe hidden structures from unlabeled data.</li>
		</ul
 <li><ins>Semi-supervised machine:</ins> 
	 <ul>
		 <li>Learning algorithms fall somewhere in between supervised and unsupervised learning, since they use both labeled and unlabeled data for training – typically a small amount of labeled data and a large amount of unlabeled data. The systems that use this method are able to considerably improve learning accuracy. Usually, semi-supervised learning is chosen when the acquired labeled data requires skilled and relevant resources in order to train it / learn from it. Otherwise, acquiring unlabeled data generally doesn’t require additional resources.</li>
	 </ul>
 </li>
<li><ins>Reinforcement machine</ins>
	<br>
	<ul>
		<li>Learning algorithms is a learning method that interacts with its environment by producing actions and discovers errors or rewards. Trial and error search and delayed reward are the most relevant characteristics of reinforcement learning.</li><br>
	</ul>
	
<li>This method allows machines and software agents to automatically determine the ideal behavior within a specific context in order to maximize its performance. Simple reward feedback is required for the agent to learn which action is best; this is known as the reinforcement signal. </li><br>
<li>Machine learning enables analysis of massive quantities of data. While it generally delivers faster, more accurate results in order to identify profitable opportunities or dangerous risks, it may also require additional time and resources to train it properly. Combining machine learning with AI and cognitive technologies can make it even more effective in processing large volumes of information.</li>
 </ul>


 <h2>What is Artificial Intelligence?</h2>
 <ul>
	 <li>Artificial intelligence (AI) is a wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence. </li> <br>
	 <li>AI is an interdisciplinary science with multiple approaches, but advancements in machine learning and deep learning are creating a paradigm shift in virtually every sector of the tech industry. </li><br>
	 <li>The major limitation in defining AI as simply "building machines that are intelligent" is that it actually doesn't </li><br>
	 <li>While these definitions may seem abstract to the average person, they help focus the field as an area of computer science and provide a blueprint for infusing machines and programs with machine learning and other subsets of artificial intelligence. AI falls under two broad categories: </li><br>
	 <li>Narrow AI: Sometimes referred to as "Weak AI," this kind of artificial intelligence operates within a limited context and is a simulation of human intelligence. Narrow AI is often focused on performing a single task extremely well and while these machines may seem intelligent, they are operating under far more constraints and limitations than even the most basic human intelligence. </li><br>
	 <li>Artificial General Intelligence (AGI): AGI, sometimes referred to as "Strong AI," is the kind of artificial intelligence we see in films like robots androids. AGI is a machine with general intelligence and, much like a human being, it can apply that intelligence to solve any problem. </li>
 </ul>


<h2>Machine Learning and Cybersecurity</h2>
It’s important to understand that machine learning is not a panacea, but it can provide a great deal of support to a cybersecurity or IT team. While ML may have a long way to go before it can be used for threat detection on its own without human intervention, there are many tasks it can handle to level up security. <br>

<h3>Some benefits of ML include:</h3>

<ul>
	<li><ins>Classification</ins> 
		
<ul>
  <li>Programs classify data based on predetermined parameters.</li>
  </ul>
  
<li><ins>Clustering</ins>
 <ul>
  <li>For data that doesn’t fit preset parameters, ML groups data based on their similarities or anomalies.</li>
  </ul>
	<li><ins>Recommendations</ins> 
		<ul>
  <li>Programs learn from past choices, inputs and associations to recommend approaches and decisions.</li>
  </ul>
	<li><ins>Generative frameworks</ins>
		<ul>
  <li>Based on past data inputs, programs generate possibilities that can be applied to data that hadn’t encountered those specific inputs before.</li>
  </ul>
	<li><ins>Predictions</ins> 
		<ul>
  <li>Programs forecast based on data sets and past outcomes.</li>
		</ul>
</ul>



<h2>Conclusion</h2>

AI and ML are becoming integral to cybersecurity, and already are in many ways. While they can be used at different levels and capacities, there are algorithms and techniques that can make an organization's security run more smoothly and free up a security team’s time for other important tasks.



<h2> Presentation</h2>

<a href="https://docs.google.com/presentation/d/1DOIEpOQXTDK7qWWfVAHIWJN1cl16HsN2/edit?usp=sharing&ouid=110228847857413878764&rtpof=true&sd=true"> Blockchain and Cryptocurrency</a>


<h2> Hands-On Labs</h2>

<a href = "https://drive.google.com/file/d/1Vw2j5EedXWBvHjhGMm0xyMLyopgPtZZn/view?usp=sharing"> The Blockchain Game </a>

<h2> Additional Resources</h2>
